
# how to configure the augmentations
# it's also possible to copy paste here for a finer control
defaults:
  - _self_
  - augmentations: asymmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "byol-pretrain-dataset"
method: "byol"
backbone:
  name: "resnet18"
method_kwargs:
  proj_hidden_dim: 4096
  proj_output_dim: 256
  pred_hidden_dim: 8192
momentum:
  base_tau: 0.99
  final_tau: 1.0
data:
  dataset: "custom"
  #train_path: "/staff/tord/Workspace/fybr_data/ssl_vehicle_classification/experiment_1/pretrain"
  train_path: "/tf/data/pretrain"
  val_path: None
  #val_path: "datasets/imagenet100/val"
  #format: "image_folder"
  format: "dali"
  num_workers: 12
  no_labels: True

augmentations:
  - rrc:
      enabled: True
      crop_min_scale: 0.7
      crop_max_scale: 1.0
    color_jitter:
      enabled: False
      brightness: 0.4
      contrast: 0.4
      saturation: 0.2
      hue: 0.1
      prob: 0.8
    grayscale:
      enabled: False
      prob: 0.2
    gaussian_blur:
      enabled: True
      prob: 0.1
    solarization:
      enabled: False
      prob: 0.1
    equalization:
      enabled: False
      prob: 0.0
    horizontal_flip:
      enabled: True
      prob: 0.5
    crop_size: 224
    num_crops: 2
    mean: [0.26965522, 0.32239996, 0.25173148]
    std: [0.111902, 0.10507919, 0.10958937]
optimizer:
  name: "lars"
  batch_size: 256
  lr: 0.01
  weight_decay: 1e-6
  classifier_lr: 0.01
  kwargs:
    clip_lr: True
    eta: 0.002
    exclude_bias_n_norm: True
scheduler:
  name: "warmup_cosine"
checkpoint:
  enabled: True
  #dir: "trained_models"
  dir: "/tf/output/"
  resume_from_checkpoint: False
  frequency: 5
auto_resume:
  enabled: False

wandb:
  enabled: True
  name: "byol_pretrain_larger_images"
  entity: "norsar_ai"
  project: "ssl_das_classification"
  offline: False

auto_umap:
  enabled: True
  frequency: 10
  dir: "/tf/output"

  
# overwrite PL stuff
max_epochs: 800
devices: [0]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16
precision: 16
